import java.io.IOException;
import java.util.*;
import java.lang.String;
        
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.conf.*;
import org.apache.hadoop.io.*;
import org.apache.hadoop.mapred.*;
import org.apache.hadoop.mapred.RecordReader;
import org.apache.hadoop.util.*;


public class MyFileInputFormat extends FileInputFormat<LongWritable, Text> {

@Override
public RecordReader<LongWritable, Text> createRecordReader( 
    InputSplit input, JobConf job, Reporter reporter)
    throws IOException {

    reporter.setStatus(input.toString());
    return new MyRecordReader(job, (FileSplit)input);

}

@Override
protected boolean isSplitable(FileSystem fs, Path filename) {
// 輸入文件不分片
return false;
}

} 
